{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLPCL23Qwa1X6/zClYofKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Qianq0625/autoencoder-test/blob/main/9_13_final_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense, LeakyReLU, ReLU, BatchNormalization, UpSampling2D, Conv2D, MaxPool2D, Flatten, Reshape, Softmax\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "HtcZEJc61nWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset file and generate sequences\n",
        "\n",
        "# read dataset.csv\n",
        "Filename = \"ID002_filtered\"\n",
        "dataSet = pd.read_csv(\"/content/\" + Filename + \".csv\").to_numpy()\n",
        "# set axes\n",
        "all = np.array(dataSet[:,[1,2,3]])\n",
        "time = np.array(dataSet[:,[0]])\n",
        "\n",
        "# scale data\n",
        "t = MinMaxScaler()\n",
        "figure()\n",
        "plt.plot(all)\n",
        "t.fit(all)\n",
        "all = t.transform(all)\n",
        "\n",
        "figure()\n",
        "plt.plot(all)\n",
        "\n",
        "# convert numpy to tensor\n",
        "all_data = torch.from_numpy(all)\n",
        "time_data = torch.from_numpy(time)\n",
        "\n",
        "# number of input columns\n",
        "n_inputs = all_data.shape[1]\n",
        "inputs = all_data.shape[0]\n",
        "print(n_inputs)\n",
        "print(inputs)\n",
        "time_n_inputs = time_data.shape[1]\n",
        "time_inputs = time_data.shape[0]\n",
        "print(time_n_inputs)\n",
        "print(time_inputs)"
      ],
      "metadata": {
        "id": "edDRd6mMDk0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate sequences\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "l_min = 14  # the Minimum value\n",
        "l_interval = 4 # the interval value\n",
        "l_max = 18  # the Maximum value\n",
        "saveflag = True\n",
        "output_all_data = []\n",
        "for _startIdx in range(0, l_min, l_interval):\n",
        "  for l_Sequence in range(l_min, l_max + l_interval, l_interval):\n",
        "    startIdx = _startIdx \n",
        "    \n",
        "    while (startIdx + l_Sequence < inputs):\n",
        "      #for i in range(0, l_Sequence):\n",
        "      sequence = all_data[startIdx:startIdx+l_Sequence,:]\n",
        "\n",
        "      output_all_data.append(np.array(sequence))\n",
        "      startIdx += round(l_Sequence * (3 / 4))\n",
        "\n",
        "\n",
        "#plot sequences\n",
        "\"\"\"\n",
        "Change the image background to black by hiding the coordinates of the output \n",
        "and making the lines thicker to generate the desired image dataset\n",
        "\"\"\"\n",
        "\n",
        "for i in range(0,len(output_all_data),1):\n",
        "  fig = plt.figure(figsize = (5,5));\n",
        "  temp_array = np.array(output_all_data[i])\n",
        "  axes = fig.gca()\n",
        "\n",
        "  axes.set_ylim(0,1)                 \n",
        "  axes.plot(temp_array,linewidth=11.5)\n",
        "  axes.patch.set_facecolor(\"black\")                 \n",
        "  plt.xticks(alpha=0)\n",
        "  plt.tick_params(axis='x', width=0)\n",
        "  plt.yticks(alpha=0)\n",
        "  plt.tick_params(axis='y', width=0)\n",
        "\n",
        "  if saveflag:\n",
        "    plt.savefig(\"/content/Figures/\" + Filename + \"_\" + str(i) + \".png\")\n",
        "\n",
        "\n",
        "output_all_data = np.array(output_all_data)\n",
        "print(\"The number of sequences: \", output_all_data.shape[0])\n",
        "nbSeq=output_all_data.shape[0] #1443 954 2321 953 498 1436\n",
        "\n",
        "\n",
        "#!rm -rf Figures/  #Clear image folder"
      ],
      "metadata": {
        "id": "gYhBbMkJEq83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make image set become .tar files and download\n",
        "import os, tarfile\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "def make_targz_one_by_one(output_filename, source_dir):\n",
        "  tar = tarfile.open(output_filename,\"w\")\n",
        "  for root,dir_name,files_list in os.walk(source_dir):\n",
        "    for file in files_list:\n",
        "      pathfile = os.path.join(root, file)\n",
        "      tar.add(pathfile)\n",
        "  tar.close()\n",
        " \n",
        "  files.download(output_filename)\n",
        " \n",
        "make_targz_one_by_one('image14-18.tar', '/content/Figures')"
      ],
      "metadata": {
        "id": "qO0aOHsePBmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf \"/content/Figures/image14-18 (4).tar\" -C \"/content/Figures/\"  #Load dataset tar and unzip it"
      ],
      "metadata": {
        "id": "bQa-5ixmPKT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -d /content/data/2w /content/Figures/2w.zip #Load dataset zip and unzip it"
      ],
      "metadata": {
        "id": "cWmdNE3yJlm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load datasets and resize images to RGB images with colour lines\n",
        "\n",
        "image_w=28\n",
        "image_h=28\n",
        "\n",
        "array_of_img = [] # this if for store all of the image data\n",
        "# this function is for read image.\n",
        "\n",
        "for filename in os.listdir(r'/content/data/2w/2w black 3/content/Figures/'):\n",
        "        print(filename) #just for test\n",
        "        #img is used to store the image data \n",
        "        img_path = \"/content/data/2w/2w black 3/content/Figures/\" + filename\n",
        "        img = cv2.imread(img_path)\n",
        "        img = img[45:320,45:320] #cut white area in blackground and then resize images to (28,28)\n",
        "        img = cv2.resize(img, None, fx=image_w/img.shape[0], fy=image_h/img.shape[1])\n",
        "      \n",
        "        img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # make BGR into RGB\n",
        "        array_of_img.append(img_rgb)\n",
        "        #print(img)\n",
        "        #print(array_of_img)\n",
        "\n",
        "image_input = np.array(array_of_img)\n",
        "\n",
        "#X_train, X_test = train_test_split(image_input, test_size=0.33, random_state=1)\n",
        "#Splitting the train and test sets, as it does not make sense to divide the data set proportionally for unlabelled data\n",
        "X_train = image_input\n",
        "X_test = image_input"
      ],
      "metadata": {
        "id": "EqVXPaJ53Zvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load datasets and resize images to grey images with white lines\n",
        "\n",
        "image_w=28\n",
        "image_h=28\n",
        "\n",
        "array_of_img = [] # this if for store all of the image data\n",
        "# this function is for read image,the input is directory name.\n",
        "\n",
        "for filename in os.listdir(r'/content/data/2w/2w black 3/content/Figures/'):\n",
        "        print(filename) #just for test\n",
        "        #img is used to store the image data \n",
        "        img_path = \"/content/data/2w/2w black 3/content/Figures/\" + filename\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, None, fx=image_w/img.shape[0], fy=image_h/img.shape[1])\n",
        "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #convert images to greyscale for analysis\n",
        "        ret, thresh = cv2.threshold(gray, 0,255, cv2.THRESH_BINARY) # fix the threshold to generate binarized images\n",
        "        cv2_imshow(thresh)\n",
        "        array_of_img.append(thresh)\n",
        "\n",
        "image_input = np.array(array_of_img)\n",
        "\n",
        "\n",
        "X_train = image_input\n",
        "X_test = image_input"
      ],
      "metadata": {
        "id": "t0axHKU1Lkur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# images nomilization\n",
        "\n",
        "#normalise \n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.astype('float32') / 255\n",
        "X_train = np.reshape(X_train, (len(X_train), 28, 28, 3))  # adapt this if using `channels_first` image data format\n",
        "X_test = np.reshape(X_test, (len(X_test), 28, 28, 3))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "\n",
        "#gray\n",
        "#X_train = np.reshape(X_train, (len(X_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "#X_test = np.reshape(X_test, (len(X_test), 28, 28, 1))  # adapt this if using `channels_first` image data format\n"
      ],
      "metadata": {
        "id": "WFvkZegB3m1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add noise to test de-noising autoencoder\n",
        "def noise(array):\n",
        "    \"\"\"\n",
        "    Adds random noise to each image in the supplied array.\n",
        "    \"\"\"\n",
        "\n",
        "    noise_factor = 0.4\n",
        "    noisy_array = array + noise_factor * np.random.normal(\n",
        "        loc=0.0, scale=1.0, size=array.shape\n",
        "    )\n",
        "\n",
        "    return np.clip(noisy_array, 0.0, 1.0)\n",
        "\n",
        "noisy_train_data = noise(X_train)\n",
        "noisy_test_data = noise(X_test)\n",
        "\n",
        "# Create a copy of the data with added noise\n",
        "noisy_train_data = noise(X_train)\n",
        "noisy_test_data = noise(X_test)\n",
        "\n",
        "# Display the train data and a version of it with added noise\n",
        "display(X_train, noisy_train_data)"
      ],
      "metadata": {
        "id": "gm0TP-6VO2Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show generated images and check it\n",
        "n = 8\n",
        "plt.figure(figsize=(40, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow((X_train[i]* 255 ).astype(np.uint8))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "slTWqRonQG2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn + flatten\n",
        "#The encoder part consists of four convolutional layers, which are transformed into one-dimensional data using 'Flatten' operation, and then compressed to 64 dimensions by a fully-connected layer\n",
        "#The decoder part consists of similar fully-connected layers, which are transformed into three-dimensional data using 'Reshape' operation, and then four similar convolutional layers, resulting in a reconstructed output with the same dimensionality as the input data.\n",
        "\n",
        "#input\n",
        "input_img = Input(shape=(28, 28, 3))  \n",
        "\n",
        "############\n",
        "# Encoding #\n",
        "############\n",
        "\n",
        "# Conv1 #\n",
        "x = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', strides=(2, 2), padding='same')(input_img)\n",
        "\n",
        "# Conv2 #\n",
        "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Conv 3 #\n",
        "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', strides=(2, 2), padding='same')(x)\n",
        "\n",
        "# Conv 4 #\n",
        "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "x = Flatten()(x)  #128\n",
        "x = Dense(4*4*8, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(4*4*8/2.0, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "# bottleneck\n",
        "n_bottleneck = 4*4*8/2.0\n",
        "encoded = Dense(n_bottleneck, activation='relu')(x)\n",
        "\n",
        "\n",
        "############\n",
        "# Decoding #\n",
        "############\n",
        "\n",
        "x = Dense(4*4*8/2.0, activation='relu')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(4*4*8, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Reshape((4,4,8))(x)\n",
        "\n",
        "# DeConv1\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# DeConv2\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# DeConv3\n",
        "x = Conv2D(8, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "\n",
        "# DeConv4\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "#output\n",
        "decoded = Conv2D(3, (3, 3), activation='relu', padding='same')(x)\n",
        "\n",
        "\n",
        "# Declare the model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "#autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.summary()\n",
        "plot_model(autoencoder, 'autoencoder_no_compress.png', show_shapes=True) #Generating structural diagrams"
      ],
      "metadata": {
        "id": "72fMgQRnQgW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check model layers\n",
        "for i in range(len(autoencoder.layers)):\n",
        "  print(autoencoder.get_layer(index=i).output) #0-23 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcj4xepu4tbn",
        "outputId": "f699b074-8ab7-4b6b-d70b-7a33d93d6c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 16), dtype=tf.float32, name=None), name='conv2d/Relu:0', description=\"created by layer 'conv2d'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 7, 7, 8), dtype=tf.float32, name=None), name='conv2d_1/Relu:0', description=\"created by layer 'conv2d_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 8), dtype=tf.float32, name=None), name='conv2d_2/Relu:0', description=\"created by layer 'conv2d_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 8), dtype=tf.float32, name=None), name='conv2d_3/Relu:0', description=\"created by layer 'conv2d_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense/Relu:0', description=\"created by layer 'dense'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='batch_normalization/batchnorm/add_1:0', description=\"created by layer 'batch_normalization'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_1/Relu:0', description=\"created by layer 'dense_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='batch_normalization_1/batchnorm/add_1:0', description=\"created by layer 'batch_normalization_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_2/Relu:0', description=\"created by layer 'dense_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='dense_4/Relu:0', description=\"created by layer 'dense_4'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='batch_normalization_2/batchnorm/add_1:0', description=\"created by layer 'batch_normalization_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='dense_5/Relu:0', description=\"created by layer 'dense_5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), name='batch_normalization_3/batchnorm/add_1:0', description=\"created by layer 'batch_normalization_3'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 8), dtype=tf.float32, name=None), name='reshape/Reshape:0', description=\"created by layer 'reshape'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 4, 4, 8), dtype=tf.float32, name=None), name='conv2d_4/Relu:0', description=\"created by layer 'conv2d_4'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 8), dtype=tf.float32, name=None), name='up_sampling2d/resize/ResizeNearestNeighbor:0', description=\"created by layer 'up_sampling2d'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 8), dtype=tf.float32, name=None), name='conv2d_5/Relu:0', description=\"created by layer 'conv2d_5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 8), dtype=tf.float32, name=None), name='up_sampling2d_1/resize/ResizeNearestNeighbor:0', description=\"created by layer 'up_sampling2d_1'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 14, 14, 8), dtype=tf.float32, name=None), name='conv2d_6/Relu:0', description=\"created by layer 'conv2d_6'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 8), dtype=tf.float32, name=None), name='up_sampling2d_2/resize/ResizeNearestNeighbor:0', description=\"created by layer 'up_sampling2d_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 16), dtype=tf.float32, name=None), name='conv2d_7/Relu:0', description=\"created by layer 'conv2d_7'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name=None), name='conv2d_8/Relu:0', description=\"created by layer 'conv2d_8'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model and save it\n",
        "# fit the autoencoder model to reconstruct input\n",
        "history = autoencoder.fit(X_train, X_train, epochs=100, batch_size=12, shuffle=True, validation_data=(X_test,X_test))\n",
        "# plot evaluation results\n",
        "loss,acc = autoencoder.evaluate(X_train, X_train, batch_size=12)\n",
        "print(\"loss:\" ,loss)\n",
        "print(\"acc:\" ,acc)\n",
        "\n",
        "figure(4)\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# define an encoder model (without the decoder)\n",
        "encoder = Model(inputs=input_img, outputs=encoded)\n",
        "# plot the encoder strcture\n",
        "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\n",
        "# save the encoder to file\n",
        "encoder.save('encoder.h5')\n",
        "\n",
        "# define an decoder model (without the encoder)\n",
        "decoder = Model(inputs=encoded, outputs=decoded)\n",
        "# plot the encoder strcture\n",
        "plot_model(decoder, 'decoder_no_compress.png', show_shapes=True)\n",
        "# save the encoder to file\n",
        "decoder.save('decoder.h5')\n",
        "\n",
        "# test decode results and original image\n",
        "decoded_imgs = autoencoder.predict(X_test)\n",
        "\n",
        "\n",
        "n = 5\n",
        "\n",
        "plt.figure(figsize=(40, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i +1)\n",
        "    #plt.imshow(X_test[i].reshape(28,28))\n",
        "    plt.imshow((X_test[i]* 255 ).astype(np.uint8))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i+1+n)\n",
        "    plt.imshow((decoded_imgs[i]* 255).astype(np.uint8))\n",
        "    #plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cwlEs6h04v15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the difference in rgb between the reconstruction and the original image\n",
        "n = 10\n",
        "img_orig_rgb = []\n",
        "img_re_rgb = []\n",
        "img_diff_rgb = []\n",
        "#len(X_test)\n",
        "for i in range(0,10,1):\n",
        "    R1 = np.sum(X_test[i,:,:,0])\n",
        "    G1 = np.sum(X_test[i,:,:,1])\n",
        "    B1 = np.sum(X_test[i,:,:,2])\n",
        "    rgb1 = R1 + G1 + B1\n",
        "    img_orig_rgb.append(rgb1)\n",
        "    print(img_orig_rgb)\n",
        "\n",
        "    R2 = np.sum(decoded_imgs[i,:,:,0])\n",
        "    G2 = np.sum(decoded_imgs[i,:,:,1])\n",
        "    B2 = np.sum(decoded_imgs[i,:,:,2])\n",
        "    rgb2 = R2 + G2 + B2\n",
        "    img_re_rgb.append(rgb2)\n",
        "    print(img_re_rgb)\n",
        "\n",
        "    img_diff = img_re_rgb[i] - img_orig_rgb[i]\n",
        "    img_diff_rgb.append(img_diff)\n",
        "    print(img_diff_rgb)\n",
        "\n",
        "    diff_rgb_mean = np.mean(img_diff_rgb)\n",
        "    diff_rgb_max = np.max(img_diff_rgb)  \n",
        "    diff_rgb_min = np.min(img_diff_rgb)  \n",
        "    diff_rgb_std = np.std(img_diff_rgb)  \n",
        "    diff_rgb_median = np.median(img_diff_rgb)\n",
        "    print(\"mean:\",diff_rgb_mean)\n",
        "    print(\"max:\",diff_rgb_max)\n",
        "    print(\"min:\",diff_rgb_min)\n",
        "    print(\"std:\",diff_rgb_std)\n",
        "    print(\"median:\",diff_rgb_median)\n",
        "\n",
        "# Plot clustering results\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "result = encoder.predict(X_test)\n",
        "len_mlist = result.shape[0]+1\n",
        "mlist = list(range(1,len_mlist))\n",
        "mlist1 = np.array(mlist)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "z = []\n",
        "x = result[:,0]\n",
        "y = result[:,1]\n",
        "z = result[:,2]\n",
        "#gender_labels = np.random.choice([0, 1], 35)\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(x,y,z)\n",
        "#ax.scatter(x,y,z,c=mlist,cmap=plt.cm.Blues,edgecolor='none',s=20)\n",
        "#ax1.plot(x1,y1,z1)\n",
        "\n",
        "plt.show()\n",
        "#for i in range(len(y)):\n",
        "\n",
        "    #plt.text(x[i]*1.01, y[i]*1.01, z[i]*1.01, s = '%d' % (int(i)), fontsize=10, fontstretch = 'condensed', color = \"black\", style = \"italic\", weight = \"light\", verticalalignment='center', horizontalalignment='right',rotation=15)\n",
        "#plt.savefig('result.png')\n",
        "#plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "rGwY3gnMT120"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add softmax to encoder part and build a new classification model\n",
        "base_model = tf.keras.models.load_model('/content/encoder.h5')\n",
        "base_model.load_weights('encoder.h5')\n",
        "\n",
        "X = base_model.output\n",
        "predictions = Dense(64, activation='softmax')(X)\n",
        "newmodel = Model(inputs=base_model.input, outputs=predictions)\n",
        "for layer in base_model.layers:   #Freeze already trained layers\n",
        "  layer.trainable = False\n",
        "newmodel.summary()\n",
        "\n",
        "print(predictions)\n",
        "\n",
        "#test pattern1\n",
        "clf_train = newmodel.predict(X_train)\n",
        "clf_test = newmodel.predict(X_test)\n",
        "\n",
        "newmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy']) \n",
        "loss, acc = newmodel.evaluate(X_test,clf_test)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Acc:\", acc)\n",
        "print(\"softmax output:\", clf_test)\n",
        "\n",
        "encoder_test = encoder.predict(X_test)\n",
        "print(\"encoder output:\", encoder_test)\n",
        "\n",
        "# plot images and corresponding 64X1 Probabilistic results\n",
        "n = 5\n",
        "\n",
        "plt.figure(figsize=(40, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i+1)\n",
        "    plt.imshow((X_test[i]* 255 ).astype(np.uint8))\n",
        "    #plt.imshow((result[1]).reshape(64,1))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    ax = plt.subplot(2, n, i+n+1)\n",
        "    #plt.imshow(X_test[i].reshape(28,28))\n",
        "    plt.imshow((clf_test[i]).reshape(64,1))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    print(clf_test[i])\n",
        "    "
      ],
      "metadata": {
        "id": "-pihEzvhW4F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test similar images\n",
        "#calculate the difference between the classification results of two similar images\n",
        "n = 2\n",
        "#len(X_test)\n",
        "for i in range(0,n,1):\n",
        "    #print(clf_test[1,:])\n",
        "    R = np.sum(clf_test[i,:])\n",
        "    G = np.sum(encoder_test[i,:])\n",
        "    print(R)\n",
        "    print(G)\n",
        "\n",
        "for i in range(0,n,1):\n",
        "  x = clf_test[0,:] \n",
        "  y = clf_test[1,:]\n",
        "  #print(x)\n",
        "  #print(y)\n",
        "  d=np.sqrt(np.sum(np.square(x-y)))\n",
        "  print(d)"
      ],
      "metadata": {
        "id": "B5IxKLAKYY7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}